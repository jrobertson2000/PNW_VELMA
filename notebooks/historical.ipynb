{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loose-glossary",
   "metadata": {},
   "source": [
    "# Historical Ellsworth (1984-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decreased-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import __init__\n",
    "import scripts.config as config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from natsort import natsorted\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from functools import reduce\n",
    "from statsmodels.iolib.smpickle import load_pickle\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wanted-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "\n",
    "XSMALL_SIZE = 6\n",
    "SMALL_SIZE = 7\n",
    "MEDIUM_SIZE = 9\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)  # fontsize of the figure title\n",
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "supreme-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcms = ['canesm2_RCP85', 'ccsm4_RCP85', 'giss_e2_h_RCP85', 'noresm1_m_RCP85', 'PRISM']\n",
    "sim_start = pd.to_datetime('01-01-1984')\n",
    "sim_end = pd.to_datetime('12-31-2020')\n",
    "\n",
    "# Output figure folder\n",
    "out_dir = config.data_path.parents[0] / 'figs' / 'sims_{}_{}'.format(sim_start.year % 100, sim_end.year % 100)\n",
    "try:\n",
    "    out_dir.mkdir(parents=True)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Import driver data\n",
    "temp_files = []\n",
    "precip_files = []\n",
    "for gcm in [x for x in gcms if x!='PRISM']:\n",
    "    temp_file_path = config.velma_data / 'temp' / '{}_{}_{}_temp.csv'.format(gcm, \n",
    "                                                                             sim_start.year % 100,\n",
    "                                                                             sim_end.year % 100)\n",
    "    temp_file = pd.read_csv(temp_file_path, names=['temp'])\n",
    "    temp_file.index = pd.date_range(sim_start, sim_end)\n",
    "    temp_files.append(temp_file)\n",
    "    \n",
    "    precip_file_path = config.velma_data / 'precip' / '{}_{}_{}_ppt.csv'.format(gcm, \n",
    "                                                                                sim_start.year % 100, \n",
    "                                                                                sim_end.year % 100)\n",
    "    precip_file = pd.read_csv(precip_file_path, names=['precip'])\n",
    "    precip_file.index = pd.date_range(sim_start, sim_end)\n",
    "    precip_files.append(precip_file)\n",
    "\n",
    "\n",
    "# PRISM data has a different naming convention because the precip is gauge/PRISM average\n",
    "temp_file_path = config.velma_data / 'temp' / 'PRISM_{}_{}_temp.csv'.format(sim_start.year % 100, \n",
    "                                                                            sim_end.year % 100)\n",
    "temp_file = pd.read_csv(temp_file_path, names=['temp'])\n",
    "temp_file.index = sim_range\n",
    "temp_files.append(temp_file)\n",
    "\n",
    "precip_file_path = config.velma_data / 'precip' / 'PRISM_{}_{}_gauge_avg_ppt.csv'.format(sim_start.year % 100, \n",
    "                                                                                         sim_end.year % 100)\n",
    "precip_file = pd.read_csv(precip_file_path, names=['precip'])\n",
    "precip_file.index = sim_range\n",
    "precip_files.append(precip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "objective-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import results files\n",
    "\n",
    "scenarios = ['historical']\n",
    "\n",
    "dailies = []\n",
    "annuals = []\n",
    "\n",
    "# Import daily and annual results\n",
    "# Results in nested lists ([x][y], for x management scenarios and y GCMs)\n",
    "for scenario in scenarios:\n",
    "    dailies_scenario = []\n",
    "    annuals_scenario = []\n",
    "    scenario_dir = config.velma_data.parents[1] / 'results' / scenario\n",
    "    dirs = os.listdir(scenario_dir)\n",
    "    for directory in dirs:\n",
    "        results_dir = scenario_dir / 'ellsworth_{}_{}_{}_{}'.format(scenario,\n",
    "                                                                    sim_start.year % 100,\n",
    "                                                                    sim_end.year % 100,\n",
    "                                                                    gcm)\n",
    "        results_dir = scenario_dir / directory\n",
    "\n",
    "        daily_results = pd.read_csv(results_dir / 'DailyResults.csv')\n",
    "\n",
    "        # Format datetime\n",
    "        jday_pad = daily_results['Day'].apply(lambda x: str(x).zfill(3))\n",
    "        str_year = daily_results['Year'].apply(lambda x: str(x))\n",
    "        rng = pd.to_datetime((str_year + jday_pad), format='%Y%j')\n",
    "        daily_results.index = rng\n",
    "        dailies_scenario.append(daily_results)\n",
    "\n",
    "#         annual_results = pd.read_csv(results_dir / 'AnnualResults.csv')\n",
    "#         annuals_scenario.append(annual_results)\n",
    "        \n",
    "    dailies.append(dailies_scenario)\n",
    "#     annuals.append(annuals_scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-premises",
   "metadata": {},
   "source": [
    "# Climate drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-fifteen",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "biblical-organization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a56c8819124a29904052f9cd18a4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "fig, axes = plt.subplots(ncols=2, nrows=3, figsize=(7, 6))\n",
    "cmap = sns.color_palette('tab10', len(gcms))\n",
    "lim_factor = 0.5  # Padding value for min and max ylimits\n",
    "\n",
    "leftcols = ['Yearly average temperature', 'Yearly min 7-day average', 'Yearly max 7-day average']\n",
    "rightcols = ['{}, GCM mean'.format(x) for x in leftcols]\n",
    "ylabs = np.repeat(['Degrees (C)' for x in leftcols], 2)\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    z = [x.groupby(pd.Grouper(freq='M')).mean() for x in temp_files]\n",
    "    temp_y_avg = pd.concat([x.groupby(pd.Grouper(freq='y')).mean() for x in z], axis=1)\n",
    "\n",
    "    z = [x.groupby(pd.Grouper(freq='7d')).mean() for x in temp_files]\n",
    "    yearly_7day_min = pd.concat([x.groupby(pd.Grouper(freq='y')).min() for x in z], axis=1)\n",
    "\n",
    "    yearly_7day_max = pd.concat([x.groupby(pd.Grouper(freq='y')).max() for x in z], axis=1)\n",
    "\n",
    "    dfs = []\n",
    "    for df in [temp_y_avg, yearly_7day_min, yearly_7day_max]:\n",
    "        df.columns = gcms\n",
    "        df = df[(df.index.year >= sim_start.year+1)]\n",
    "        dfs.append(df)\n",
    "        \n",
    "    for j, ax in enumerate(axes):\n",
    "        dfs[j].plot(ax=axes[j, 0], linewidth=0.9, color=cmap)\n",
    "        axes[j, 0].title.set_text(leftcols[j])\n",
    "        dfs[j].mean(axis=1).plot(ax=axes[j, 1], label=scenario, color='dimgray')\n",
    "        axes[j, 1].title.set_text(rightcols[j])\n",
    "        ymin = np.floor(np.min(dfs[j].to_numpy()) - (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        ymax = np.ceil(np.max(dfs[j].to_numpy()) + (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        axes[j, 0].set_ylim([ymin, ymax])\n",
    "        axes[j, 1].set_ylim([ymin, ymax])\n",
    "        axes[j, 0].get_legend().remove()\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_xlim([sim_start + pd.DateOffset(years=1), sim_end])\n",
    "    ax.xaxis.label.set_visible(False)\n",
    "    ax.set_ylabel(ylabs[i])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99], h_pad=0.01, w_pad=0.00)\n",
    "leg = axes[0, 0].legend(loc='upper left', bbox_to_anchor=(0, 1.3), fancybox=True, ncol=5, fontsize='small')\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(2.0)\n",
    "\n",
    "fig.savefig(out_dir / 'temperature.png', bbox_inches='tight', dpi=export_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-balance",
   "metadata": {},
   "source": [
    "### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "supreme-outline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c449427f664f908c859123d901fbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "fig, axes = plt.subplots(ncols=2, nrows=3, figsize=(7, 6))\n",
    "cmap = sns.color_palette('tab10', len(gcms))\n",
    "lim_factor = 0.5  # Padding value for min and max ylimits\n",
    "\n",
    "leftcols = ['Yearly total precipitation', '5-year total precipitation', 'Yearly max 7-day sum']\n",
    "rightcols = ['{}, GCM mean'.format(x) for x in leftcols]\n",
    "ylabs = np.repeat(['Degrees (C)' for x in leftcols], 2)\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    z = [x.groupby(pd.Grouper(freq='Y')).mean() for x in precip_files]\n",
    "    ppt_y_sum = pd.concat([x for x in z], axis=1)\n",
    "\n",
    "    z = [x.groupby(pd.Grouper(freq='5Y')).mean() for x in precip_files]\n",
    "    ppt_5y_sum = pd.concat([x for x in z], axis=1)\n",
    "\n",
    "    z = [x.groupby(pd.Grouper(freq='7d')).sum() for x in temp_files]\n",
    "    yearly_7day_max = pd.concat([x.groupby(pd.Grouper(freq='y')).max() for x in z], axis=1)\n",
    "\n",
    "    dfs = []\n",
    "    for df in [ppt_y_sum, ppt_5y_sum, yearly_7day_max]:\n",
    "        df.columns = gcms\n",
    "        dfs.append(df)\n",
    "        \n",
    "    for j, ax in enumerate(axes):\n",
    "        dfs[j].plot(ax=axes[j, 0], linewidth=0.9, color=cmap)\n",
    "        axes[j, 0].title.set_text(leftcols[j])\n",
    "        dfs[j].mean(axis=1).plot(ax=axes[j, 1], label=scenario, color='dimgray')\n",
    "        axes[j, 1].title.set_text(rightcols[j])\n",
    "        ymin = np.floor(np.min(dfs[j].to_numpy()) - (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        ymax = np.ceil(np.max(dfs[j].to_numpy()) + (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        axes[j, 0].set_ylim([ymin, ymax])\n",
    "        axes[j, 1].set_ylim([ymin, ymax])\n",
    "        axes[j, 0].get_legend().remove()\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_xlim([sim_start + pd.DateOffset(years=1), sim_end])\n",
    "    ax.xaxis.label.set_visible(False)\n",
    "    ax.set_ylabel(ylabs[i])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99], h_pad=0.01, w_pad=0.00)\n",
    "leg = axes[0, 0].legend(loc='upper left', bbox_to_anchor=(0, 1.3), fancybox=True, ncol=5, fontsize='small')\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(2.0)\n",
    "\n",
    "fig.savefig(out_dir / 'precipitation.png', bbox_inches='tight', dpi=export_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-girlfriend",
   "metadata": {},
   "source": [
    "## Runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "parliamentary-things",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cde858bf2c3478c92ab298ff609b5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "fig, axes = plt.subplots(ncols=2, nrows=4, figsize=(7, 6))\n",
    "cmap = sns.color_palette('tab10', len(gcms))\n",
    "lim_factor = 0.5  # Padding value for min and max ylimits\n",
    "\n",
    "leftcols = ['Yearly min 7-day average', 'Yearly max 7-day average', 'Yearly sum flow', 'Yearly mean flow']\n",
    "rightcols = ['{}, GCM mean'.format(x) for x in leftcols]\n",
    "ylabs = np.repeat(['Runoff (mm)' for x in leftcols], 2)\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    z = [x.groupby(pd.Grouper(freq='7d')).mean()['Runoff_All(mm/day)_Delineated_Average'] for x in dailies[i]]\n",
    "    yearly_7day_min = pd.concat([x.groupby(pd.Grouper(freq='y')).min() for x in z], axis=1)\n",
    "\n",
    "    yearly_7day_max = pd.concat([x.groupby(pd.Grouper(freq='y')).max() for x in z], axis=1)\n",
    "\n",
    "    z = [x.groupby(pd.Grouper(freq='y')).sum()['Runoff_All(mm/day)_Delineated_Average'] for x in dailies[i]]\n",
    "    yearly_sum = pd.concat(z, axis=1)\n",
    "\n",
    "    z = [x.groupby(pd.Grouper(freq='y')).mean()['Runoff_All(mm/day)_Delineated_Average'] for x in dailies[i]]\n",
    "    yearly_mean = pd.concat(z, axis=1)\n",
    "\n",
    "    dfs = []\n",
    "    for df in [yearly_7day_min, yearly_7day_max, yearly_sum, yearly_mean]:\n",
    "        df.columns = gcms\n",
    "        df = df[(df.index.year >= sim_start.year+1)]\n",
    "        dfs.append(df)\n",
    "        \n",
    "    for j, ax in enumerate(axes):\n",
    "        dfs[j].plot(ax=axes[j, 0], linewidth=0.7, color=cmap)\n",
    "        axes[j, 0].title.set_text(leftcols[j])\n",
    "        dfs[j].mean(axis=1).plot(ax=axes[j, 1], label=scenario, color='dimgray')\n",
    "        axes[j, 1].title.set_text(rightcols[j])\n",
    "        axes[j, 0].get_legend().remove()\n",
    "        ymin = np.floor(np.min(dfs[j].to_numpy()) - (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        ymax = np.ceil(np.max(dfs[j].to_numpy()) + (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        axes[j, 0].set_ylim([ymin, ymax])\n",
    "        axes[j, 1].set_ylim([ymin, ymax])\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_xlim([sim_start + pd.DateOffset(years=1), sim_end])\n",
    "    ax.xaxis.label.set_visible(False)\n",
    "    ax.set_ylabel(ylabs[i])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99], h_pad=0.01, w_pad=0.00)\n",
    "leg = axes[0, 0].legend(loc='upper left', bbox_to_anchor=(0, 1.5), fancybox=True, ncol=5, fontsize='small')\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(2.0)\n",
    "\n",
    "fig.savefig(out_dir / 'runoff.png', bbox_inches='tight', dpi=export_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-fellow",
   "metadata": {},
   "source": [
    "## Stream temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "concrete-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cell writer files\n",
    "\n",
    "cell_results = []\n",
    "for scenario in scenarios:\n",
    "    cell_results_scenario = []\n",
    "    scenario_dir = config.velma_data.parents[1] / 'results' / scenario\n",
    "    for gcm in gcms:\n",
    "        cell_paths = []\n",
    "        results_dir = scenario_dir / 'ellsworth_{}_{}_{}_{}'.format(scenario,\n",
    "                                                                    sim_start.year % 100,\n",
    "                                                                    sim_end.year % 100,\n",
    "                                                                    gcm)\n",
    "        for file in os.listdir(results_dir):\n",
    "            if file.startswith('Cell_'):\n",
    "                cell_paths.append(file)\n",
    "        \n",
    "        nodes = []\n",
    "        for path in cell_paths:\n",
    "            nodes.append(path.split('_')[-1])\n",
    "        \n",
    "        cell_paths_sorted = [x for _,x in natsorted(zip(nodes,cell_paths))]\n",
    "        \n",
    "        for path in [cell_paths_sorted[0]]:  # Only need the first cell, which is the Ellsworth mouth/outlet\n",
    "            cell_result = pd.read_csv(results_dir / path)\n",
    "            jday_pad = cell_result['Jday'].apply(lambda x: str(x).zfill(3))\n",
    "            str_year = cell_result['Year'].apply(lambda x: str(x))\n",
    "            cell_result['date'] = str_year + jday_pad\n",
    "            rng = pd.to_datetime(cell_result['date'], format='%Y%j')\n",
    "            cell_result.index = rng\n",
    "            cell_results_scenario.append(cell_result)\n",
    "    \n",
    "    cell_results.append(cell_results_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "great-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct VELMA stream temperature seasonal bias using pre-trained regression model\n",
    "# *** Not sure if this correction is still valid considering the non-linear seasonal changes of the climate projections ***\n",
    "\n",
    "olsmodel = load_pickle(config.data_path.parents[0] / 'models' / 'stream_temp_correction_ols.pickle')\n",
    "\n",
    "stream_temps_corrected = []\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    stream_temps_scenario = []\n",
    "    for j, gcm in enumerate(gcms):\n",
    "        z = cell_results[i][j]['Water_Surface_Temperature(degrees_C)']\n",
    "        \n",
    "        day = 24 * 60 * 60\n",
    "        year = 365.2425 * day\n",
    "        timestamp_secs = pd.to_datetime(z.index)\n",
    "        timestamp_secs = timestamp_secs.map(datetime.datetime.timestamp)\n",
    "        year_cos = np.cos(timestamp_secs * (2 * np.pi / year))\n",
    "        year_sin = np.sin(timestamp_secs * (2 * np.pi / year))\n",
    "\n",
    "        y = pd.DataFrame(data=np.column_stack([z, year_cos, year_sin]), columns=['temp', 'year_cos', 'year_sin'])\n",
    "        y.index = z.index\n",
    "        y['air_temp_3day_avg'] = y['temp'].rolling(3, min_periods=0).mean()\n",
    "\n",
    "        y = sm.add_constant(y)\n",
    "        y['streamtemp_corrected'] = olsmodel.predict(y)\n",
    "        \n",
    "        stream_temps_scenario.append(y['streamtemp_corrected'])\n",
    "    \n",
    "    stream_temps_corrected.append(stream_temps_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "executed-status",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba5f4c5db6049b1a08ae91513b9060a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "fig, axes = plt.subplots(ncols=2, nrows=3, figsize=(7, 5))\n",
    "cmap = sns.color_palette('tab10', len(gcms))\n",
    "lim_factor = 0.5  # Padding value for min and max ylimits\n",
    "\n",
    "leftcols = ['Yearly mean', 'Yearly min 7-day average', 'Yearly max 7-day average']\n",
    "rightcols = ['{}, GCM mean'.format(x) for x in leftcols]\n",
    "ylabs = np.repeat(['Degrees (C)' for x in leftcols], 2)\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    z = [x for x in stream_temps_corrected[i]]\n",
    "    yearly_mean = pd.concat([x.groupby(pd.Grouper(freq='y')).mean() for x in z], axis=1)\n",
    "    \n",
    "    z = [x.groupby(pd.Grouper(freq='7d')).mean() for x in stream_temps_corrected[i]]\n",
    "    yearly_7day_min = pd.concat([x.groupby(pd.Grouper(freq='y')).min() for x in z], axis=1)\n",
    "    \n",
    "    z = [x.groupby(pd.Grouper(freq='7d')).mean() for x in stream_temps_corrected[i]]\n",
    "    yearly_7day_max = pd.concat([x.groupby(pd.Grouper(freq='y')).max() for x in z], axis=1)\n",
    "\n",
    "    dfs = []\n",
    "    for df in [yearly_mean, yearly_7day_min, yearly_7day_max]:\n",
    "        df.columns = gcms\n",
    "        df = df[(df.index.year >= sim_start.year+1)]\n",
    "        dfs.append(df)\n",
    "        \n",
    "    for j, ax in enumerate(axes):\n",
    "        dfs[j].plot(ax=axes[j, 0], linewidth=0.7, color=cmap)\n",
    "        axes[j, 0].title.set_text(leftcols[j])\n",
    "        dfs[j].mean(axis=1).plot(ax=axes[j, 1], label=scenario, color='dimgray')\n",
    "        axes[j, 1].title.set_text(rightcols[j])\n",
    "        ymin = np.floor(np.min(dfs[j].to_numpy()) - (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        ymax = np.ceil(np.max(dfs[j].to_numpy()) + (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        axes[j, 0].set_ylim([ymin, ymax])\n",
    "        axes[j, 1].set_ylim([ymin, ymax])\n",
    "        axes[j, 0].get_legend().remove()\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_xlim([sim_start + pd.DateOffset(years=1), sim_end])\n",
    "    ax.xaxis.label.set_visible(False)\n",
    "    ax.set_ylabel(ylabs[i])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99], h_pad=0.01, w_pad=0.00)\n",
    "leg = axes[0, 0].legend(loc='upper left', bbox_to_anchor=(0, 1.7), fancybox=True, ncol=5, fontsize='small')\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(2.0)\n",
    "\n",
    "fig.savefig(out_dir / 'stream_temperature.png', bbox_inches='tight', dpi=export_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-zambia",
   "metadata": {},
   "source": [
    "## Stream chemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "actual-headquarters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8667c01e907748bfb498b53489a676ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "fig, axes = plt.subplots(ncols=2, nrows=4, figsize=(6.5, 5.5))\n",
    "cmap = sns.color_palette('tab10', len(gcms))\n",
    "lim_factor = 0.5  # Padding value for min and max ylimits\n",
    "\n",
    "leftcols = ['NH4', 'N03', 'DON', 'DOC']\n",
    "rightcols = ['{}, GCM mean'.format(x) for x in leftcols]\n",
    "ylabs = np.repeat(['gN/m2', 'gN/m2', 'gN/m2', 'gC/m2'], 2)\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    z = [x[['NH4(gN/m2)_Layer1', 'NH4(gN/m2)_Layer2', 'NH4(gN/m2)_Layer3', 'NH4(gN/m2)_Layer4']].sum(axis=1) for x in cell_results[i]]\n",
    "    nh4 = [x.groupby(pd.Grouper(freq='y')).mean() for x in z]\n",
    "\n",
    "    z = [x[['NO3(gN/m2)_Layer1', 'NO3(gN/m2)_Layer2', 'NO3(gN/m2)_Layer3', 'NO3(gN/m2)_Layer4']].sum(axis=1) for x in cell_results[i]]\n",
    "    no3 = [x.groupby(pd.Grouper(freq='y')).mean() for x in z]\n",
    "\n",
    "    z = [x[['DON(gN/m2)_Layer1', 'DON(gN/m2)_Layer2', 'DON(gN/m2)_Layer3', 'DON(gN/m2)_Layer4']].sum(axis=1) for x in cell_results[i]]\n",
    "    don = [x.groupby(pd.Grouper(freq='y')).mean() for x in z]\n",
    "\n",
    "    z = [x[['DOC(gC/m2)_Layer1', 'DOC(gC/m2)_Layer2', 'DOC(gC/m2)_Layer3', 'DOC(gC/m2)_Layer4']].sum(axis=1) for x in cell_results[i]]\n",
    "    doc = [x.groupby(pd.Grouper(freq='y')).mean() for x in z]\n",
    "\n",
    "    dfs = []\n",
    "    for df in [nh4, no3, don, doc]:\n",
    "        df = pd.concat(df, axis=1)\n",
    "        df.columns = gcms\n",
    "        df = df[(df.index.year >= sim_start.year+1)]\n",
    "        dfs.append(df)\n",
    "        \n",
    "    for j, ax in enumerate(axes):\n",
    "        dfs[j].plot(ax=axes[j, 0], linewidth=0.7, color=cmap)\n",
    "        axes[j, 0].title.set_text(leftcols[j])\n",
    "        dfs[j].mean(axis=1).plot(ax=axes[j, 1], label=scenario, color='dimgray')\n",
    "        axes[j, 1].title.set_text(rightcols[j])\n",
    "        ymin = np.min(dfs[j].to_numpy()) - (np.std(dfs[j].to_numpy()) * lim_factor)\n",
    "        ymax = np.max(dfs[j].to_numpy()) + (np.std(dfs[j].to_numpy()) * lim_factor)\n",
    "        axes[j, 0].set_ylim([ymin, ymax])\n",
    "        axes[j, 1].set_ylim([ymin, ymax])\n",
    "        axes[j, 0].get_legend().remove()\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_xlim([sim_start + pd.DateOffset(years=1), sim_end])\n",
    "    ax.xaxis.label.set_visible(False)\n",
    "    ax.set_ylabel(ylabs[i])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99], h_pad=0.01, w_pad=0.00)\n",
    "leg = axes[0, 0].legend(loc='upper left', bbox_to_anchor=(0, 1.5), fancybox=True, ncol=5, fontsize='small')\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(2.0)\n",
    "\n",
    "fig.savefig(out_dir / 'stream_chemistry.png', bbox_inches='tight', dpi=export_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-valuation",
   "metadata": {},
   "source": [
    "# Carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "enormous-halloween",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5358ae0b3f4ed89b6c2c08fdb95388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "fig, axes = plt.subplots(ncols=2, nrows=5, figsize=(7, 7))\n",
    "cmap = sns.color_palette('tab10', len(gcms))\n",
    "lim_factor = 0.5  # Padding value for min and max ylimits\n",
    "\n",
    "leftcols = ['agBiomass Pool', 'bgBiomass Pool', 'agLitter Pool', 'bgLitter Pool', 'Humus Pool']\n",
    "rightcols = ['{}, GCM mean'.format(x) for x in leftcols]\n",
    "ylabs = np.repeat(['gC/m2' for x in leftcols], 2)\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    ag_biomass_pool = [x['agBiomass_Pool(gC/m2)_Delineated_Average'] for x in dailies[i]]\n",
    "    bg_biomass_pool = [x['bgBiomass_Pool(gC/m2)_Delineated_Average'] for x in dailies[i]]\n",
    "    ag_litter_pool = [x['agLitter_Pool(gC/m2)_Delineated_Average'] for x in dailies[i]]\n",
    "    bg_litter_pool = [x['bgLitter_Pool(gC/m2)_Delineated_Average'] for x in dailies[i]]\n",
    "    humus_pool = [x['Humus_Pool(gC/m2)_Delineated_Average'] for x in dailies[i]]\n",
    "\n",
    "    dfs = []\n",
    "    for df in [ag_biomass_pool, bg_biomass_pool, ag_litter_pool, bg_litter_pool, humus_pool]:\n",
    "        df = pd.concat(df, axis=1)\n",
    "        df.columns = gcms\n",
    "        df = df[(df.index.year >= sim_start.year+1)]\n",
    "        dfs.append(df)\n",
    "        \n",
    "    for j, ax in enumerate(axes):\n",
    "        dfs[j].plot(ax=axes[j, 0], linewidth=0.7, color=cmap)\n",
    "        axes[j, 0].title.set_text(leftcols[j])\n",
    "        dfs[j].mean(axis=1).plot(ax=axes[j, 1], label=scenario, color='dimgray')\n",
    "        axes[j, 1].title.set_text(rightcols[j])\n",
    "        ymin = np.floor(np.min(dfs[j].to_numpy()) - (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        ymax = np.ceil(np.max(dfs[j].to_numpy()) + (np.std(dfs[j].to_numpy()) * lim_factor))\n",
    "        axes[j, 0].set_ylim([ymin, ymax])\n",
    "        axes[j, 1].set_ylim([ymin, ymax])\n",
    "        axes[j, 0].get_legend().remove()\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_xlim([sim_start + pd.DateOffset(years=1), sim_end])\n",
    "    ax.xaxis.label.set_visible(False)\n",
    "    ax.set_ylabel(ylabs[i])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "leg = axes[0, 0].legend(loc='upper left', bbox_to_anchor=(0, 1.7), fancybox=True, ncol=5, fontsize='small')\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(2.0)\n",
    "\n",
    "fig.savefig(out_dir / 'biomass_carbon.png', bbox_inches='tight', dpi=export_dpi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnc_velma",
   "language": "python",
   "name": "tnc_velma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
