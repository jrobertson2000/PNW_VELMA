{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "medical-extent",
   "metadata": {},
   "source": [
    "# Selecting a GCM projection based on historical observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prescription-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import __init__\n",
    "import scripts.config as config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import datetime\n",
    "from sklearn.svm import SVR\n",
    "from natsort import natsorted\n",
    "import geopandas as gpd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import os\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "royal-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "\n",
    "XSMALL_SIZE = 6\n",
    "SMALL_SIZE = 7\n",
    "MEDIUM_SIZE = 9\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)  # fontsize of the figure title\n",
    "plt.rcParams['figure.dpi'] = 140"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-treaty",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "second-memorabilia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\anaconda3\\envs\\tnc_velma\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3166: DtypeWarning: Columns (9,13,37,43,45) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Average PRISM and Naselle gauge precipitation\n",
    "gauge = pd.read_csv(config.daily_ppt.parents[0] / 'GHCND_USC00455774_1929_2020.csv', parse_dates=True, index_col=5)\n",
    "gauge['SNOW'].fillna(0, inplace=True)\n",
    "gauge['SNOW_SWE'] = gauge['SNOW'] / 13\n",
    "gauge['PRCP_TOT'] = gauge['PRCP'] + gauge['SNOW_SWE']\n",
    "gauge_precip = gauge[['PRCP_TOT']]\n",
    "\n",
    "prism_precip = pd.read_csv(str(config.daily_ppt.parents[0] / 'prism_ppt_1981_2020_daily.csv'), parse_dates=True, index_col=0)\n",
    "\n",
    "# Expand precip record to full date range in case some days are missing\n",
    "hist_start = pd.to_datetime('01-01-1981')\n",
    "hist_end = pd.to_datetime('12-31-2020')\n",
    "rng = pd.date_range(hist_start, hist_end)\n",
    "date_df = pd.DataFrame(index=rng)\n",
    "gauge_precip_velma = date_df.merge(gauge_precip, left_index=True, right_index=True, how='left')\n",
    "prism_precip_velma = date_df.merge(prism_precip, left_index=True, right_index=True, how='left')\n",
    "\n",
    "prism_precip_mean = pd.concat([gauge_precip_velma, prism_precip_velma], axis=1)\n",
    "prism_precip_mean['avg_precip'] = prism_precip_mean.mean(axis=1)\n",
    "obs_p = prism_precip_mean.loc[:, ['avg_precip']]\n",
    "\n",
    "# Air temperature\n",
    "temp_path = config.daily_temp_mean.parents[0] / 'prism_temp_1981_2020_daily.csv'\n",
    "obs_t = pd.read_csv(temp_path, parse_dates=True, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "framed-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GCM precipitation \n",
    "wrf_dir = config.data_path / 'precip' / 'VIC_WRF_EllsworthCr'\n",
    "gcm_avg_dir = wrf_dir / 'sim_avg'\n",
    "cols = ['year', 'month', 'day', 'access1.0_RCP45', 'access1.0_RCP85', 'access1.3_RCP85',\n",
    "        'bcc-csm1.1_RCP85', 'canesm2_RCP85', 'ccsm4_RCP85', 'csiro-mk3.6.0_RCP85',\n",
    "        'fgoals-g2_RCP85', 'gfdl-cm3_RCP85', 'giss-e2-h_RCP85', 'miroc5_RCP85',\n",
    "        'mri-cgcm3_RCP85', 'noresm1-m_RCP85']\n",
    "\n",
    "arr = np.loadtxt(gcm_avg_dir / 'sim_avg_ppt.gz')\n",
    "proj_sims_ppt = pd.DataFrame(data=arr, columns=cols)\n",
    "proj_sims_ppt.index = pd.to_datetime(proj_sims_ppt[['year', 'month', 'day']])\n",
    "proj_sims_ppt = proj_sims_ppt.drop(['year', 'month', 'day'], axis=1)\n",
    "proj_sims_ppt_d = proj_sims_ppt.groupby(pd.Grouper(freq='d')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cardiac-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get temperature\n",
    "forc_dir = config.data_path / 'precip' / 'WRF_frcs_EllsworthCr_forcings'\n",
    "gcm_avg_forc_dir = forc_dir / 'sim_avg'\n",
    "cols = ['year', 'month', 'day', 'access1.0_RCP45', 'access1.0_RCP85', 'access1.3_RCP85',\n",
    "        'bcc-csm1.1_RCP85', 'canesm2_RCP85', 'ccsm4_RCP85', 'csiro-mk3.6.0_RCP85',\n",
    "        'fgoals-g2_RCP85', 'gfdl-cm3_RCP85', 'giss-e2-h_RCP85', 'miroc5_RCP85',\n",
    "        'mri-cgcm3_RCP85', 'noresm1-m_RCP85']\n",
    "\n",
    "arr = np.loadtxt(gcm_avg_forc_dir / 'sim_avg_temp.gz')\n",
    "proj_sims_temp = pd.DataFrame(data=arr, columns=cols)\n",
    "proj_sims_temp.index = pd.to_datetime(proj_sims_temp[['year', 'month', 'day']])\n",
    "proj_sims_temp = proj_sims_temp.drop(['year', 'month', 'day'], axis=1)\n",
    "proj_sims_temp_d = proj_sims_temp.groupby(pd.Grouper(freq='d')).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-workplace",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "minimal-tragedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a931115686415ca40039b82fcadd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Year')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot monthly and yearly average temps of all GCMs vs. historical\n",
    "colors = sns.color_palette('Dark2', 13)\n",
    "hist_start = pd.to_datetime('01-01-1981')\n",
    "hist_end = pd.to_datetime('12-31-2020')\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 2))\n",
    "for i, sim in enumerate(proj_sims_temp):\n",
    "    sim_data = proj_sims_temp_d.loc[:, sim]\n",
    "    sim_subset = sim_data[(sim_data.index >= hist_start) & (sim_data.index <= hist_end)]\n",
    "    sim_group = sim_subset.groupby(pd.Grouper(freq='y')).mean()\n",
    "    sim_group.plot(label=sim, color=colors[i], alpha=0.5, ax=ax, linewidth=0.8)\n",
    "obs_t.groupby(pd.Grouper(freq='y')).mean().plot(label='Observed (PRISM)', color='black', linewidth=1.2, ax=ax)\n",
    "ax.get_legend().remove()\n",
    "ax.set_ylabel('Yearly average temperature (C)')\n",
    "ax.set_xlabel('Year')\n",
    "# fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "recreational-tulsa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "access1.0_RCP45        244.685423\n",
       "access1.0_RCP85        240.909473\n",
       "access1.3_RCP85        241.146225\n",
       "bcc-csm1.1_RCP85       234.109330\n",
       "canesm2_RCP85          242.554440\n",
       "ccsm4_RCP85            242.046603\n",
       "csiro-mk3.6.0_RCP85    244.131986\n",
       "fgoals-g2_RCP85        240.210223\n",
       "gfdl-cm3_RCP85         242.113721\n",
       "giss-e2-h_RCP85        242.058648\n",
       "miroc5_RCP85           242.635993\n",
       "mri-cgcm3_RCP85        237.612569\n",
       "noresm1-m_RCP85        233.282778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_subset = proj_sims_temp_d[(proj_sims_temp_d.index >= hist_start) & (proj_sims_temp_d.index <= hist_end)]\n",
    "np.abs(sim_subset.groupby(pd.Grouper(freq='y')).mean().sub(obs_t['temp'], axis=0)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "surgical-guess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9deaa7d227de45419dbcf1476cba18b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Year')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "# Plot residuals from observed temp\n",
    "colors = sns.color_palette('Dark2', 13)\n",
    "hist_start = pd.to_datetime('01-01-1981')\n",
    "hist_end = pd.to_datetime('12-31-2020')\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 2))\n",
    "\n",
    "obs = obs_t.groupby(pd.Grouper(freq='y')).mean()\n",
    "for i, sim in enumerate(proj_sims_temp_d):\n",
    "    sim_data = proj_sims_temp_d.loc[:, sim]\n",
    "    sim_subset = sim_data[(sim_data.index >= hist_start) & (sim_data.index <= hist_end)]\n",
    "    sim_group = sim_subset.groupby(pd.Grouper(freq='y')).mean()\n",
    "    sim_resid = sim_group - obs.iloc[:,0]\n",
    "    sim_resid.plot(label=sim, color=colors[i], alpha=0.5, ax=ax, linewidth=0.8)\n",
    "    ax.axline((11, 0), slope=0, linewidth=1, color='black', linestyle='--')\n",
    "ax.set_ylabel('Residual from observed temperature (C)')\n",
    "ax.set_xlabel('Year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "strange-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fed8a2a65c4f3695f6f9dbf4ac0375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot monthly and yearly total precip of all GCMs vs. historical\n",
    "colors = sns.color_palette('Dark2', 13)\n",
    "hist_start = pd.to_datetime('01-01-1981')\n",
    "hist_end = pd.to_datetime('12-31-2020')\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 2))\n",
    "for i, sim in enumerate(proj_sims_ppt_d):\n",
    "    sim_data = proj_sims_ppt_d.loc[:, sim]\n",
    "    sim_subset = sim_data[(sim_data.index >= hist_start) & (sim_data.index <= hist_end)]\n",
    "    sim_group = sim_subset.groupby(pd.Grouper(freq='y')).sum()\n",
    "    sim_group.plot(label=sim, color=colors[i], alpha=0.5, ax=ax, linewidth=0.8)\n",
    "#     ax.get_legend().remove()\n",
    "obs_p.groupby(pd.Grouper(freq='y')).sum().plot(label='Observed (PRISM)', color='black', linewidth=1.2, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "recorded-telescope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-12-31     2486.400\n",
       "2025-12-31    15754.125\n",
       "2030-12-31    13132.075\n",
       "2035-12-31    11740.375\n",
       "2040-12-31    13557.100\n",
       "2045-12-31    13685.900\n",
       "2050-12-31    15541.925\n",
       "2055-12-31    12113.000\n",
       "2060-12-31    13971.975\n",
       "2065-12-31    12389.725\n",
       "2070-12-31    14401.850\n",
       "2075-12-31    12134.450\n",
       "2080-12-31    15453.175\n",
       "2085-12-31    15023.025\n",
       "2090-12-31    13899.500\n",
       "2095-12-31    15418.450\n",
       "2100-12-31    12128.325\n",
       "Freq: 5A-DEC, Name: noresm1-m_RCP85, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "civilian-smart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-01-01 00:00:00')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "unsigned-asian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348d30e56c4d43fe917f34470928227c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot projected average temps of all GCMs\n",
    "plt.close('all')\n",
    "colors = sns.color_palette('Dark2', 13)\n",
    "proj_start = pd.to_datetime('01-01-2020')\n",
    "proj_end = pd.to_datetime('12-31-2099')\n",
    "fig, axes = plt.subplots(ncols=1, nrows=2, figsize=(5, 5))\n",
    "for i, sim in enumerate(proj_sims_temp):\n",
    "    sim_data = proj_sims_temp_d.loc[:, sim]\n",
    "    sim_subset = sim_data[(sim_data.index >= proj_start) & (sim_data.index <= proj_end)]\n",
    "    sim_group = sim_subset.groupby(pd.Grouper(freq='5y')).mean()\n",
    "    sim_group.plot(label=sim, color=colors[i], alpha=0.5, ax=axes[0])\n",
    "    \n",
    "    sim_data = proj_sims_ppt_d.loc[:, sim]\n",
    "    sim_subset = sim_data[(sim_data.index >= pd.to_datetime(str(proj_start.year-5))) & (sim_data.index <= proj_end)]\n",
    "    sim_group = sim_subset.groupby(pd.Grouper(freq='5y')).sum()\n",
    "    sim_group.plot(label=sim, color=colors[i], alpha=0.5, ax=axes[1])\n",
    "    axes[1].set_xlim(('2020', '2100'))\n",
    "    \n",
    "axes[0].set_ylabel('Degrees (C)')\n",
    "axes[0].set_title('Projected Temperature (5yr mean)')\n",
    "\n",
    "axes[1].set_ylabel('Precipitation (mm)')\n",
    "axes[1].set_xlabel('Projected Year')\n",
    "axes[1].set_title('Projected Precipitation (5yr sum)')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=1, nrows=2, figsize=(6.5, 5.5))\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# Deltas vs Observed historical normals\n",
    "\n",
    "deltas = pd.DataFrame(np.column_stack([delta_t1, delta_p1, delta_t2, delta_p2]),\n",
    "                      columns=['delta_t1', 'delta_p1', 'delta_t2', 'delta_p2'], \n",
    "                      index=proj_temp_end.columns)\n",
    "deltas = deltas.reindex(distances_norm.index)\n",
    "\n",
    "labels = ['{} {}'.format(x, y) for x, y in zip(range(1, len(distances_norm.index)+1), distances_norm.index)]\n",
    "nums = [x for x in range(1, len(distances_norm.index)+1)]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=2, figsize=(6.5, 5.5))\n",
    "scatter = axes[0].scatter(deltas['delta_p1'], deltas['delta_t1'], color='tab:blue', s=10)\n",
    "scatter = axes[1].scatter(deltas['delta_p2'], deltas['delta_t2'], color='tab:blue', s=10)\n",
    "\n",
    "for i, num in enumerate(nums):\n",
    "    axes[0].annotate(num, (deltas['delta_p1'][i]+0.005, deltas['delta_t1'][i]+0.005))\n",
    "    axes[1].annotate(num, (deltas['delta_p2'][i]+0.005, deltas['delta_t2'][i]+0.005))\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=x, markerfacecolor='tab:blue', markersize=5) for x in labels]\n",
    "\n",
    "# Concentric circles around mean\n",
    "avg_t, avg_p = np.mean(delta_t1), np.mean(delta_p1)\n",
    "axes[0].scatter(avg_p, avg_t, s=1000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[0].scatter(avg_p, avg_t, s=10000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[0].scatter(avg_p, avg_t, s=50000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[0].scatter(avg_p, avg_t, color='red', s=3)\n",
    "axes[0].annotate('Mean', (avg_p+0.005, avg_t+0.005), color='red')\n",
    "\n",
    "avg_t, avg_p = np.mean(delta_t2), np.mean(delta_p2)\n",
    "axes[1].scatter(avg_p, avg_t, s=1000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[1].scatter(avg_p, avg_t, s=10000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[1].scatter(avg_p, avg_t, s=50000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[1].scatter(avg_p, avg_t, color='red', s=3)\n",
    "axes[1].annotate('Mean', (avg_p+0.005, avg_t+0.005), color='red')\n",
    "\n",
    "# Highlight selected models\n",
    "selected_models = [5,2,4,1]\n",
    "model_types = ['warm', 'hot', 'hot+wet', 'mean']\n",
    "for model in selected_models:\n",
    "    axes[0].scatter(deltas.iloc[model-1, 1], deltas.iloc[model-1, 0], s=10, color='tab:orange')\n",
    "    axes[1].scatter(deltas.iloc[model-1, 3], deltas.iloc[model-1, 2], s=10, color='tab:orange')\n",
    "\n",
    "axes[0].legend(handles=legend_elements, loc='right', bbox_to_anchor=(1.45, 0.5), fancybox=True, ncol=1)\n",
    "plt.suptitle('Projected changes in T and P')\n",
    "axes[0].set_title('Deltas vs. Observed historic normals')\n",
    "axes[1].set_title('Deltas vs. GCM historic normals')\n",
    "axes[0].set_ylabel(r'$\\Delta T$ $(\\degree C)$')\n",
    "axes[0].set_xlabel(r'$\\Delta P$ $(\\%)$')\n",
    "axes[1].set_ylabel(r'$\\Delta T$ $(\\degree C)$')\n",
    "axes[1].set_xlabel(r'$\\Delta P$ $(\\%)$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-missile",
   "metadata": {},
   "source": [
    "## Calculate historical metrics of GCMs\n",
    "\n",
    "Using some metrics from Rupp et al. (2013)\n",
    "\n",
    "Nino indices from NOAA https://www.ncdc.noaa.gov/teleconnections/enso/indicators/sst/\n",
    "\n",
    "A little unclear on how precipitation is supposed to be calculated for some of these. Trend precip doesn't quite match Rupp et al., they use % change from the 100 year mean, but doing that gives really small values.\n",
    "\n",
    "https://agupubs.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fjgrd.50843&file=ReadMe.txt\n",
    "\n",
    "This uses monthly mean precip for most calculations, as Rupp does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "outside-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_start = pd.to_datetime('01-01-1981')\n",
    "hist_end = pd.to_datetime('12-31-2020')\n",
    "proj_temp_sub = proj_sims_temp_d[(proj_sims_temp_d.index >= hist_start) & (proj_sims_temp_d.index <= hist_end)]\n",
    "proj_ppt_sub = proj_sims_ppt_d[(proj_sims_ppt_d.index >= hist_start) & (proj_sims_ppt_d.index <= hist_end)]\n",
    "\n",
    "\n",
    "# Get monthly means\n",
    "monthly_t = proj_temp_sub.groupby(pd.Grouper(freq='m')).mean()\n",
    "monthly_obs_t = obs_t.groupby(pd.Grouper(freq='m')).mean()\n",
    "monthly_p = proj_ppt_sub.groupby(pd.Grouper(freq='m')).mean()\n",
    "monthly_obs_p = obs_p.groupby(pd.Grouper(freq='m')).mean()\n",
    "\n",
    "\n",
    "# Yearly mean temp/precip\n",
    "mean_t = monthly_t.groupby(pd.Grouper(freq='y')).mean().mean(axis=0)  # deg C\n",
    "mean_obs_t = monthly_obs_t.groupby(pd.Grouper(freq='y')).mean().mean(axis=0)\n",
    "mean_p = monthly_p.groupby(pd.Grouper(freq='y')).sum().mean(axis=0)  # mm/yr\n",
    "mean_obs_p = monthly_obs_p.groupby(pd.Grouper(freq='y')).sum().mean(axis=0)\n",
    "\n",
    "\n",
    "# Correlation with observed monthly temp/precip\n",
    "mat_t = monthly_t.copy()\n",
    "mat_t['obs'] = monthly_obs_t\n",
    "corr_t = mat_t.corr().iloc[:-1, -1]\n",
    "\n",
    "mat_p = monthly_p.copy()\n",
    "mat_p['obs'] = monthly_obs_p\n",
    "corr_p = mat_p.corr().iloc[:-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "radio-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean amplitude of seasonal cycle (warmest-coldest month, wettest-driest month, where monthly precip is % of mean annual total)\n",
    "seasonal_amp_t = monthly_t.groupby(pd.Grouper(freq='y')).max() - monthly_t.groupby(pd.Grouper(freq='y')).min()   # deg C\n",
    "seasonal_amp_t = seasonal_amp_t.mean(axis=0)\n",
    "seasonal_amp_obs_t = monthly_obs_t.groupby(pd.Grouper(freq='y')).max() - monthly_obs_t.groupby(pd.Grouper(freq='y')).min()   # deg C\n",
    "seasonal_amp_obs_t = seasonal_amp_obs_t.mean(axis=0)\n",
    "\n",
    "z = proj_ppt_sub.groupby(pd.Grouper(freq='y')).sum()\n",
    "x = np.repeat(np.array(z), repeats=12, axis=0)\n",
    "yearly_tots_p = pd.DataFrame(x)\n",
    "monthly_p_sum = proj_ppt_sub.groupby(pd.Grouper(freq='m')).sum()\n",
    "monthly_perc_p = pd.DataFrame(monthly_p_sum.values /yearly_tots_p.values, columns=monthly_p.columns, index=monthly_p.index)\n",
    "seasonal_amp_p = monthly_perc_p.groupby(pd.Grouper(freq='y')).max() - monthly_perc_p.groupby(pd.Grouper(freq='y')).min()\n",
    "seasonal_amp_p = seasonal_amp_p.mean(axis=0)\n",
    "\n",
    "z = obs_p.groupby(pd.Grouper(freq='y')).sum()\n",
    "x = np.repeat(np.array(z), repeats=12, axis=0)\n",
    "yearly_tots_obs_p = pd.DataFrame(x)\n",
    "monthly_obs_p_sum = obs_p.groupby(pd.Grouper(freq='m')).sum()\n",
    "monthly_perc_obs_p = pd.DataFrame(monthly_obs_p_sum.values / yearly_tots_obs_p.values, \n",
    "                                  columns=monthly_obs_p.columns, index=monthly_obs_p.index)\n",
    "seasonal_amp_obs_p = monthly_perc_obs_p.groupby(pd.Grouper(freq='y')).max() - monthly_perc_obs_p.groupby(pd.Grouper(freq='y')).min()\n",
    "seasonal_amp_obs_p = seasonal_amp_obs_p.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "editorial-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear trend of annual temp\n",
    "trend_t = np.polyfit(x=monthly_t.groupby(pd.Grouper(freq='y')).mean().index.year, \n",
    "                     y=monthly_t.groupby(pd.Grouper(freq='y')).mean(), deg=1)[0, :]  # deg/time period (1981-2020)\n",
    "\n",
    "trend_obs_t = np.polyfit(x=monthly_obs_t.groupby(pd.Grouper(freq='y')).mean().index.year, \n",
    "                         y=monthly_obs_t.groupby(pd.Grouper(freq='y')).mean(), deg=1)[0, :]\n",
    "\n",
    "# Linear trend of annual precip, calculated as % change from period mean\n",
    "\n",
    "trend_p = np.polyfit(x=monthly_p.groupby(pd.Grouper(freq='y')).mean().index.year, \n",
    "                     y=monthly_p.groupby(pd.Grouper(freq='y')).mean(), deg=1)[0, :] # mm/time period (1981-2020)\n",
    "\n",
    "trend_obs_p = np.polyfit(x=monthly_obs_p.groupby(pd.Grouper(freq='y')).mean().index.year, \n",
    "                         y=monthly_obs_p.groupby(pd.Grouper(freq='y')).mean(), deg=1)[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dated-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance of temp calculated at aggregation periods from N=1 to N=8 years\n",
    "freqs_t = ['1y', '2y', '3y', '4y', '5y', '6y', '7y', '8y']\n",
    "vars_t = [(monthly_t.groupby(pd.Grouper(freq=freq)).var()).mean(axis=0) for freq in freqs_t]\n",
    "\n",
    "vars_obs_t = [(monthly_obs_t.groupby(pd.Grouper(freq=freq)).var()).mean(axis=0) for freq in freqs_t]\n",
    "\n",
    "\n",
    "# Coefficient of variation of precip calculated at aggregation periods from N=1 to N=8 water years (Oct to Sep)\n",
    "freqs_p = ['A-SEP', '2A-SEP', '3A-SEP', '4A-SEP', '5A-SEP', '6A-SEP', '7A-SEP', '8A-SEP']\n",
    "cvs_p = [(monthly_p.groupby(pd.Grouper(freq=freq)).std() / \n",
    "          monthly_p.groupby(pd.Grouper(freq=freq)).mean()).mean(axis=0) for freq in freqs_p]\n",
    "\n",
    "cvs_obs_p = [(monthly_obs_p.groupby(pd.Grouper(freq=freq)).std() / \n",
    "              monthly_obs_p.groupby(pd.Grouper(freq=freq)).mean()).mean(axis=0) for freq in freqs_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "virtual-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of winter temp/precip with Nino3.4 index\n",
    "nino = pd.read_table(config.data_path / 'precip' / 'sstoi.indices.txt', delim_whitespace=True, parse_dates={'date': ['YR', 'MON']}, index_col=0)\n",
    "nino_sub = nino[(nino.index >= monthly_t.index.min()) & (nino.index <= monthly_t.index.max())]\n",
    "nino_winter = nino_sub[~~nino_sub.index.month.isin([11, 12, 1, 2, 3])]\n",
    "nino_winter = nino_winter.groupby(pd.Grouper(freq='y')).mean()\n",
    "\n",
    "winter_t = proj_sims_temp_d.groupby(pd.Grouper(freq='AS-MAR')).mean()\n",
    "winter_p = proj_sims_ppt_d.groupby(pd.Grouper(freq='AS-MAR')).sum()\n",
    "winter_t_obs = obs_t.groupby(pd.Grouper(freq='AS-MAR')).mean()\n",
    "winter_p_obs = obs_p.groupby(pd.Grouper(freq='AS-MAR')).sum()\n",
    "\n",
    "winter_t = monthly_t[(monthly_t.index >= nino_sub.index.min()) & (monthly_t.index <= nino_sub.index.max())]\n",
    "winter_t = winter_t[~~winter_t.index.month.isin([1, 2, 3])]\n",
    "winter_t = winter_t.groupby(pd.Grouper(freq='y')).mean()\n",
    "winter_t['nino'] = nino_winter['NINO3.4'].values\n",
    "corr_nino_t = winter_t.corr()['nino'].drop('nino')\n",
    "\n",
    "winter_obs_t = obs_t[(obs_t.index >= nino_sub.index.min()) & (obs_t.index <= nino_sub.index.max())]\n",
    "winter_obs_t = winter_obs_t[~~winter_obs_t.index.month.isin([1, 2, 3])]\n",
    "winter_obs_t = winter_obs_t.groupby(pd.Grouper(freq='y')).mean()\n",
    "winter_obs_t['nino'] = nino_winter['NINO3.4'].values\n",
    "corr_nino_obs_t = winter_obs_t.corr()['nino'].drop('nino')\n",
    "\n",
    "winter_p = proj_sims_ppt_d[(proj_sims_ppt_d.index >= nino_sub.index.min()) & (proj_sims_ppt_d.index <= nino_sub.index.max())]\n",
    "winter_p = winter_p[~~winter_p.index.month.isin([1, 2, 3])]\n",
    "winter_p = winter_p.groupby(pd.Grouper(freq='y')).mean()\n",
    "winter_p['nino'] = nino_winter['NINO3.4'].values\n",
    "corr_nino_p = winter_p.corr()['nino'].drop('nino')\n",
    "\n",
    "winter_obs_p = obs_p[(obs_p.index >= nino_sub.index.min()) & (obs_p.index <= nino_sub.index.max())]\n",
    "winter_obs_p = winter_obs_p[~~winter_obs_p.index.month.isin([1, 2, 3])]\n",
    "winter_obs_p = winter_obs_p.groupby(pd.Grouper(freq='y')).mean()\n",
    "winter_obs_p['nino'] = nino_winter['NINO3.4'].values\n",
    "corr_nino_obs_p = winter_obs_p.corr()['nino'].drop('nino')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-retro",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Compare historical metrics of GCMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "abroad-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine obs metrics\n",
    "obs_metrics = [mean_obs_t.values, mean_obs_p.values, seasonal_amp_obs_t.values, seasonal_amp_obs_p.values, \n",
    "               trend_obs_t, trend_obs_p, corr_nino_obs_t.values, corr_nino_obs_p.values] #, vars_obs_t, vars_obs_p]\n",
    "obs_metrics = obs_metrics + [x.values for x in vars_obs_t]\n",
    "obs_metrics = obs_metrics + [x.values for x in cvs_obs_p]\n",
    "obs_metrics_df = pd.DataFrame(data=np.column_stack(obs_metrics), \n",
    "                              columns=['mean_t', 'mean_p', 'seasonal_amp_t', 'seasonal_amp_p', 'trend_t', 'trend_p', 'nino_t', 'nino_p',\n",
    "                                       'var_t_1yr', 'var_t_2yr', 'var_t_3yr', 'var_t_4yr', 'var_t_5yr', 'var_t_6yr', 'var_t_7yr', 'var_t_8yr',\n",
    "                                       'cv_p_1yr', 'cv_p_2yr', 'cv_p_3yr', 'cv_p_4yr', 'cv_p_5yr', 'cv_p_6yr', 'cv_p_7yr', 'cv_p_8yr'], index=['obs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "congressional-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine GCM metrics\n",
    "metrics = [mean_t.values, mean_p.values, seasonal_amp_t.values, seasonal_amp_p.values, trend_t, trend_p, corr_nino_t.values, corr_nino_p.values]\n",
    "metrics = metrics + [x.values for x in vars_t]\n",
    "metrics = metrics + [x.values for x in cvs_p]\n",
    "metrics_df = pd.DataFrame(data=np.column_stack(metrics), \n",
    "                          columns=['mean_t', 'mean_p', 'seasonal_amp_t', 'seasonal_amp_p', 'trend_t', 'trend_p', 'nino_t', 'nino_p',\n",
    "                                   'var_t_1yr', 'var_t_2yr', 'var_t_3yr', 'var_t_4yr', 'var_t_5yr', 'var_t_6yr', 'var_t_7yr', 'var_t_8yr',\n",
    "                                   'cv_p_1yr', 'cv_p_2yr', 'cv_p_3yr', 'cv_p_4yr', 'cv_p_5yr', 'cv_p_6yr', 'cv_p_7yr', 'cv_p_8yr'], \n",
    "                          index=mean_t.index)\n",
    "\n",
    "metrics_df[['bias_t', 'bias_p']] = metrics_df[['mean_t', 'mean_p']] - obs_metrics_df[['mean_t', 'mean_p']].values\n",
    "obs_metrics_df['bias_t'] = 0\n",
    "obs_metrics_df['bias_p'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "orange-calcium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde6eb47b925400d81e2ac188296fdfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['bias_t', 'bias_p', 'seasonal_amp_t', 'seasonal_amp_p', 'trend_t', 'trend_p', 'nino_t', 'nino_p',\n",
    "        'var_t_1yr',  'var_t_8yr', 'cv_p_1yr', 'cv_p_8yr'] \n",
    "\n",
    "fig, axes = plt.subplots(ncols=4, nrows=3, figsize=(6, 5))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "        metrics_df.boxplot(column=[col], ax=axes.flatten()[i])\n",
    "        axes.flatten()[i].plot(np.repeat(1, len(metrics_df)), metrics_df[col], mec='k', ms=2, marker=\"o\", linestyle=\"None\")\n",
    "        axes.flatten()[i].axhline(obs_metrics_df[col].values, ls='--')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-likelihood",
   "metadata": {},
   "source": [
    "### Rank GCMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "proof-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "obs_repeat = obs_metrics_df.loc[obs_metrics_df.index.repeat(13)].reset_index(drop=True)\n",
    "E = np.abs(obs_repeat - metrics_df.values)\n",
    "E.index = metrics_df.index\n",
    "E_sum = E.sum(axis=1)\n",
    "\n",
    "# Relative Error\n",
    "rel_E = (E - E.min(axis=1)) / (E.max(axis=1) - E.min(axis=1))\n",
    "rel_E_sum = rel_E.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "continental-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "all_metrics = metrics_df.copy()\n",
    "all_metrics.loc['obs', :] = obs_metrics_df.values\n",
    "scaler = StandardScaler()\n",
    "metrics_scaled = pd.DataFrame(data=scaler.fit_transform(all_metrics), \n",
    "                              columns=all_metrics.columns, \n",
    "                              index=all_metrics.index)\n",
    "\n",
    "n_components = len(metrics_scaled.index)\n",
    "\n",
    "pca = PCA(n_components, random_state=27)\n",
    "pca.fit(metrics_scaled)\n",
    "X = pca.transform(metrics_scaled)\n",
    "loadings = pd.DataFrame(pca.components_,\n",
    "                        columns=['PC{}'.format(x) for x in range(1, len(metrics_scaled.columns)+1)],\n",
    "                        index=metrics_scaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "restricted-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Euclidean distance of models from Obs in PC1 vs. PC2 space\n",
    "\n",
    "obs_x, obs_y = loadings.loc['obs', 'PC1'], loadings.loc['obs', 'PC2']\n",
    "distances = np.sqrt((obs_x - loadings.loc[:, 'PC1'])**2 + (obs_y - loadings.loc[:, 'PC2'])**2)\n",
    "distances.columns=['distance']\n",
    "distances.drop('obs', inplace=True)\n",
    "distances_norm = (distances - distances.min())/(distances.max() - distances.min())\n",
    "distances_norm = distances_norm.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "outstanding-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d70b42e166f42869a66625f2054e011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "labels = ['{} {}'.format(x, y) for x, y in zip(range(1, len(distances_norm.index)+1), distances_norm.index)]\n",
    "nums = [x for x in range(1, len(distances_norm.index)+1)]\n",
    "\n",
    "model_ranking = distances_norm.index.insert(0, 'obs')\n",
    "loadings = loadings.reindex(model_ranking)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.5,3))\n",
    "scatter = ax.scatter(loadings['PC1'], loadings['PC2'], color='tab:blue', s=10)\n",
    "for i, num in enumerate(nums[:-1]):\n",
    "    ax.annotate(num, (loadings['PC1'][i]+0.01, loadings['PC2'][i]+0.01))\n",
    "ax.annotate('Obs', (loadings.loc['obs', 'PC1']+0.01, loadings.loc['obs', 'PC2']+0.01), color='red')\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=x, markerfacecolor='tab:blue', markersize=5) for x in labels]\n",
    "\n",
    "# Concentric circles around observed\n",
    "ax.scatter(loadings.loc['obs', 'PC1'], loadings.loc['obs', 'PC2'], s=1000, facecolors='none', color='black', linewidth=0.2)\n",
    "ax.scatter(loadings.loc['obs', 'PC1'], loadings.loc['obs', 'PC2'], s=10000, facecolors='none', color='black', linewidth=0.2)\n",
    "ax.scatter(loadings.loc['obs', 'PC1'], loadings.loc['obs', 'PC2'], s=50000, facecolors='none', color='black', linewidth=0.2)\n",
    "ax.set_ylim((-0.2, 0.8))\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='right', bbox_to_anchor=(1.45, 0.5), fancybox=True, ncol=1)\n",
    "plt.suptitle('PCA Loadings')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_xlabel('PC1')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-stand",
   "metadata": {},
   "source": [
    "## Calculating projected metrics of GCMs\n",
    "\n",
    "Based on Case et al. (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "military-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of 21st century\n",
    "end_start = pd.to_datetime('01-01-2070')\n",
    "end_end = pd.to_datetime('12-31-2099')\n",
    "\n",
    "proj_temp_end = proj_sims_temp_d[(proj_sims_temp_d.index >= end_start) & (proj_sims_temp_d.index <= end_end)]\n",
    "proj_ppt_end = proj_sims_ppt_d[(proj_sims_ppt_d.index >= end_start) & (proj_sims_ppt_d.index <= end_end)]\n",
    "\n",
    "# 30 year normals\n",
    "hist_start = pd.to_datetime('01-01-1981')\n",
    "hist_end = pd.to_datetime('12-31-2010')\n",
    "\n",
    "proj_temp_hist = proj_sims_temp_d[(proj_sims_temp_d.index >= hist_start) & (proj_sims_temp_d.index <= hist_end)]\n",
    "proj_ppt_hist = proj_sims_ppt_d[(proj_sims_ppt_d.index >= hist_start) & (proj_sims_ppt_d.index <= hist_end)]\n",
    "\n",
    "obs_t_hist = obs_t[(obs_t.index >= hist_start) & (obs_t.index <= hist_end)]\n",
    "obs_p_hist = obs_p[(obs_p.index >= hist_start) & (obs_p.index <= hist_end)]\n",
    "\n",
    "\n",
    "# Projected change in average annual T and average annual precip, 2070-2100 vs 1981-2021 normals\n",
    "mean_t = proj_temp_end.groupby(pd.Grouper(freq='y')).mean().mean(axis=0)\n",
    "mean_p = proj_ppt_end.groupby(pd.Grouper(freq='y')).sum().mean(axis=0)\n",
    "\n",
    "# Deltas from observed normals\n",
    "hist_t1 = obs_t_hist.groupby(pd.Grouper(freq='y')).mean().mean(0)\n",
    "hist_p1 = obs_p_hist.groupby(pd.Grouper(freq='y')).sum().mean(0)\n",
    "\n",
    "delta_t1 = mean_t.values - hist_t1.values\n",
    "delta_p1 = (mean_p.values - hist_p1.values) / hist_p1.values\n",
    "\n",
    "# Deltas from GCM normals\n",
    "hist_t2 = proj_temp_hist.groupby(pd.Grouper(freq='y')).mean().mean(0)\n",
    "hist_p2 = proj_ppt_hist.groupby(pd.Grouper(freq='y')).sum().mean(0)\n",
    "\n",
    "delta_t2 = mean_t.values - hist_t2.values\n",
    "delta_p2 = (mean_p.values - hist_p2.values) / hist_p2.values\n",
    "\n",
    "# # Get monthly means\n",
    "# monthly_t = proj_temp_sub.groupby(pd.Grouper(freq='m')).mean()\n",
    "# monthly_obs_t = obs_t.groupby(pd.Grouper(freq='m')).mean()\n",
    "# monthly_p = proj_ppt_sub.groupby(pd.Grouper(freq='m')).mean()\n",
    "# monthly_obs_p = obs_p.groupby(pd.Grouper(freq='m')).mean()\n",
    "\n",
    "\n",
    "# # Yearly mean temp/precip\n",
    "# mean_t = monthly_t.groupby(pd.Grouper(freq='y')).mean().mean(axis=0)  # deg C\n",
    "# mean_obs_t = monthly_obs_t.groupby(pd.Grouper(freq='y')).mean().mean(axis=0)\n",
    "# mean_p = monthly_p.groupby(pd.Grouper(freq='y')).sum().mean(axis=0)  # mm/yr\n",
    "# mean_obs_p = monthly_obs_p.groupby(pd.Grouper(freq='y')).sum().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "functioning-trunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0983fe3af7fe475abc6789bdf6ad1e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================================================\n",
    "# Deltas vs Observed historical normals\n",
    "\n",
    "deltas = pd.DataFrame(np.column_stack([delta_t1, delta_p1, delta_t2, delta_p2]),\n",
    "                      columns=['delta_t1', 'delta_p1', 'delta_t2', 'delta_p2'], \n",
    "                      index=proj_temp_end.columns)\n",
    "deltas = deltas.reindex(distances_norm.index)\n",
    "\n",
    "labels = ['{} {}'.format(x, y) for x, y in zip(range(1, len(distances_norm.index)+1), distances_norm.index)]\n",
    "nums = [x for x in range(1, len(distances_norm.index)+1)]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=2, figsize=(6.5, 5.5))\n",
    "scatter = axes[0].scatter(deltas['delta_p1'], deltas['delta_t1'], color='tab:blue', s=10)\n",
    "scatter = axes[1].scatter(deltas['delta_p2'], deltas['delta_t2'], color='tab:blue', s=10)\n",
    "\n",
    "for i, num in enumerate(nums):\n",
    "    axes[0].annotate(num, (deltas['delta_p1'][i]+0.005, deltas['delta_t1'][i]+0.005))\n",
    "    axes[1].annotate(num, (deltas['delta_p2'][i]+0.005, deltas['delta_t2'][i]+0.005))\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=x, markerfacecolor='tab:blue', markersize=5) for x in labels]\n",
    "\n",
    "# Concentric circles around mean\n",
    "avg_t, avg_p = np.mean(delta_t1), np.mean(delta_p1)\n",
    "axes[0].scatter(avg_p, avg_t, s=1000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[0].scatter(avg_p, avg_t, s=10000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[0].scatter(avg_p, avg_t, s=50000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[0].scatter(avg_p, avg_t, color='red', s=3)\n",
    "axes[0].annotate('Mean', (avg_p+0.005, avg_t+0.005), color='red')\n",
    "\n",
    "avg_t, avg_p = np.mean(delta_t2), np.mean(delta_p2)\n",
    "axes[1].scatter(avg_p, avg_t, s=1000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[1].scatter(avg_p, avg_t, s=10000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[1].scatter(avg_p, avg_t, s=50000, facecolors='none', color='black', linewidth=0.2)\n",
    "axes[1].scatter(avg_p, avg_t, color='red', s=3)\n",
    "axes[1].annotate('Mean', (avg_p+0.005, avg_t+0.005), color='red')\n",
    "\n",
    "# Highlight selected models\n",
    "selected_models = [5,2,4,1]\n",
    "model_types = ['warm', 'hot', 'hot+wet', 'mean']\n",
    "for model in selected_models:\n",
    "    axes[0].scatter(deltas.iloc[model-1, 1], deltas.iloc[model-1, 0], s=10, color='tab:orange')\n",
    "    axes[1].scatter(deltas.iloc[model-1, 3], deltas.iloc[model-1, 2], s=10, color='tab:orange')\n",
    "\n",
    "axes[0].legend(handles=legend_elements, loc='right', bbox_to_anchor=(1.45, 0.5), fancybox=True, ncol=1)\n",
    "plt.suptitle('Projected changes in T and P')\n",
    "axes[0].set_title('Deltas vs. Observed historic normals')\n",
    "axes[1].set_title('Deltas vs. GCM historic normals')\n",
    "axes[0].set_ylabel(r'$\\Delta T$ $(\\degree C)$')\n",
    "axes[0].set_xlabel(r'$\\Delta P$ $(\\%)$')\n",
    "axes[1].set_ylabel(r'$\\Delta T$ $(\\degree C)$')\n",
    "axes[1].set_xlabel(r'$\\Delta P$ $(\\%)$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "seeing-talent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giss_e2_h_RCP85 (warm)\n",
      "canesm2_RCP85 (hot)\n",
      "noresm1_m_RCP85 (hot+wet)\n",
      "ccsm4_RCP85 (mean)\n"
     ]
    }
   ],
   "source": [
    "# Selected models\n",
    "names = [deltas.iloc[model-1, :].name for model in selected_models]\n",
    "names_edit = [y.replace('-', '_') for y in [x.replace('.', '_') for x in names]]\n",
    "for name, mtype in zip(names_edit, model_types):\n",
    "    print('{} ({})'.format(name, mtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-spring",
   "metadata": {},
   "source": [
    "## Export temp and precip of all GCMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export precip\n",
    "\n",
    "# sim_start = pd.to_datetime('01-01-2020')\n",
    "# sim_end = pd.to_datetime('12-31-2099')\n",
    "\n",
    "# wrf_dir = config.data_path / 'precip' / 'VIC_WRF_EllsworthCr'\n",
    "# wrf_file = 'flux_46.40625_-123.90625'\n",
    "# wrf_cols = [\"YEAR\",\"MONTH\",\"DAY\",\"HOUR\",\"OUT_PREC\",\"OUT_PET_SHORT\",\n",
    "#             \"OUT_SWE\",\"OUT_EVAP\",\"OUT_RUNOFF\",\"OUT_BASEFLOW\",\n",
    "#             \"OUT_SOIL_MOIST0\", \"OUT_SOIL_MOIST1\",\"OUT_SOIL_MOIST2\"]\n",
    "\n",
    "# sims = ['access1.0_RCP45', 'access1.0_RCP85', 'access1.3_RCP85', 'bcc-csm1.1_RCP85', \n",
    "#         'canesm2_RCP85', 'ccsm4_RCP85', 'csiro-mk3.6.0_RCP85', 'fgoals-g2_RCP85', \n",
    "#         'gfdl-cm3_RCP85', 'giss-e2-h_RCP85', 'miroc5_RCP85', 'mri-cgcm3_RCP85', 'noresm1-m_RCP85']\n",
    "\n",
    "# # Valid file names\n",
    "# sim_names = [y.replace('-', '_') for y in [x.replace('.', '_') for x in sims]]\n",
    "\n",
    "# for i, sim in enumerate(sims):\n",
    "#     outfile_ppt = config.velma_data / 'precip' / '{}_20_99_ppt.csv'.format(sim_names[i])\n",
    "#     arr = np.loadtxt(wrf_dir / sim / 'sim_avg' / wrf_file)\n",
    "#     df = pd.DataFrame(arr, columns=wrf_cols)\n",
    "#     df.index = pd.to_datetime(df[['YEAR', 'MONTH', 'DAY']])\n",
    "#     daily_ppt = df.groupby(pd.Grouper(freq='d')).sum()['OUT_PREC']\n",
    "#     daily_ppt_sim = daily_ppt[(daily_ppt.index >= sim_start) & (daily_ppt.index <= sim_end)]\n",
    "#     daily_ppt_sim.to_csv(outfile_ppt, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export temp\n",
    "\n",
    "# sim_start = pd.to_datetime('01-01-2020')\n",
    "# sim_end = pd.to_datetime('12-31-2099')\n",
    "\n",
    "# forc_dir = config.data_path / 'precip' / 'WRF_frcs_EllsworthCr_forcings'\n",
    "# forc_file = 'forc_46.40625_-123.90625'\n",
    "# forc_cols = ['Year', 'Month', 'Day', 'Hour', 'Precip(mm)', 'Temp(C)', \n",
    "#              'Wind(m/s)', 'SWrad(W/m2)', 'LWrad(W/m2)', 'pressure(kPa)', \n",
    "#              'VaporPress(kPa)']\n",
    "\n",
    "# sims = ['access1.0_RCP45', 'access1.0_RCP85', 'access1.3_RCP85', 'bcc-csm1.1_RCP85', \n",
    "#         'canesm2_RCP85', 'ccsm4_RCP85', 'csiro-mk3.6.0_RCP85', 'fgoals-g2_RCP85', \n",
    "#         'gfdl-cm3_RCP85', 'giss-e2-h_RCP85', 'miroc5_RCP85', 'mri-cgcm3_RCP85', 'noresm1-m_RCP85']\n",
    "\n",
    "# # Valid file names\n",
    "# sim_names = [y.replace('-', '_') for y in [x.replace('.', '_') for x in sims]]\n",
    "\n",
    "# for i, sim in enumerate(sims):\n",
    "#     outfile_temp = config.velma_data / 'temp' / '{}_20_99_temp.csv'.format(sim_names[i])\n",
    "#     arr = np.loadtxt(forc_dir / sim / forc_file)\n",
    "#     df = pd.DataFrame(arr, columns=forc_cols)\n",
    "#     df.index = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "#     daily_temp = df.groupby(pd.Grouper(freq='d')).mean()['Temp(C)']\n",
    "#     daily_temp_sim = daily_temp[(daily_temp.index >= sim_start) & (daily_temp.index <= sim_end)]\n",
    "#     daily_temp_sim.to_csv(outfile_temp, header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnc_velma",
   "language": "python",
   "name": "tnc_velma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
